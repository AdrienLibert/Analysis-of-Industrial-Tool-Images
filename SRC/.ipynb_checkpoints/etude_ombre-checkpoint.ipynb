{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239fa031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af230164",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../DataBase/image7.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b8bb5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "\n",
    "l_threshold = cv2.adaptiveThreshold(l_channel, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                    cv2.THRESH_BINARY_INV, 15, -5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c110a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('ombre.jpg', thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21d2d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "    taille_noyau = (5, 5)\n",
    "    sigma = 0\n",
    "    blurred_image = cv2.GaussianBlur(image, taille_noyau, sigma)\n",
    "    \n",
    "    \n",
    "    gray = cv2.cvtColor(blurred_image, cv2.COLOR_BGR2GRAY)\n",
    "    _,thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    thresh = cv2.bitwise_not(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f983428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appliquer un flou gaussien\n",
    "taille_noyau = (5, 5)\n",
    "sigma = 0\n",
    "blurred_image = cv2.GaussianBlur(image, taille_noyau, sigma)\n",
    "\n",
    "# Convertir l'image en un espace colorimétrique différent, par exemple LAB, et utiliser le canal L\n",
    "image_lab = cv2.cvtColor(blurred_image, cv2.COLOR_BGR2Lab)\n",
    "l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "\n",
    "# Appliquer CLAHE sur le canal L pour améliorer le contraste localement\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "l_channel_clahe = clahe.apply(l_channel)\n",
    "\n",
    "# Binariser l'image en utilisant le seuil d'Otsu sur le canal L amélioré\n",
    "_, thresh = cv2.threshold(l_channel_clahe, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "# Sauvegarder ou afficher l'image résultante\n",
    "cv2.imwrite('image_sans_ombres.jpg', thresh)\n",
    "# ou cv2.imshow('Image sans ombres', thresh)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbb54d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Charger l'image\n",
    "\n",
    "# Appliquer l'ajustement du contraste\n",
    "alpha = 2.2  # Facteur de contraste (1.0 = pas de changement, >1.0 = augmente le contraste)\n",
    "beta = 25   # Facteur d'ajustement de la luminosité (valeurs positives pour éclaircir, négatives pour assombrir)\n",
    "\n",
    "# La nouvelle valeur de pixel = alpha * pixel actuel + beta\n",
    "contrasted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
    "\n",
    "cv2.imwrite('image_sans_ombres.jpg', contrasted_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d688145e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convertir l'image en niveaux de gris (si nécessaire)\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Définir le noyau pour la morphologie. La taille et la forme dépendent des spécificités de l'image.\n",
    "noyau = np.ones((5, 5), np.uint8)  # Un noyau carré de taille 5x5\n",
    "\n",
    "# Appliquer la fermeture morphologique\n",
    "image_fermee = cv2.morphologyEx(gray_image, cv2.MORPH_CLOSE, noyau)\n",
    "\n",
    "cv2.imwrite('image_sans_ombres.jpg', image_fermee)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6a6eb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Convertir l'image de BGR à LAB\n",
    "image_lab = cv2.cvtColor(image, cv2.COLOR_BGR2Lab)\n",
    "\n",
    "# Séparer les canaux L, A, et B\n",
    "l_channel, a_channel, b_channel = cv2.split(image_lab)\n",
    "\n",
    "# Enregistrer le canal L\n",
    "cv2.imwrite('l_channel.jpg', b_channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd703a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convertir l'image de BGR à HSV\n",
    "image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Séparer les canaux H, S, et V\n",
    "h_channel, s_channel, v_channel = cv2.split(image_hsv)\n",
    "\n",
    "\n",
    "# Appliquer l'ajustement du contraste\n",
    "alpha = 1  # Facteur de contraste (1.0 = pas de changement, >1.0 = augmente le contraste)\n",
    "beta = -1   # Facteur d'ajustement de la luminosité (valeurs positives pour éclaircir, négatives pour assombrir)\n",
    "\n",
    "# La nouvelle valeur de pixel = alpha * pixel actuel + beta\n",
    "contrasted_image = cv2.convertScaleAbs(s_channel, alpha=alpha, beta=beta)\n",
    "\n",
    "cv2.imwrite('image_sans_ombres.jpg', contrasted_image)\n",
    "# Enregistrer le canal H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f4e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rgb_to_yiq(image_rgb):\n",
    "    transform_matrix = np.array([[0.299, 0.587, 0.114],\n",
    "                                 [0.596, -0.274, -0.322],\n",
    "                                 [0.211, -0.523, 0.312]])\n",
    "    image_yiq = np.dot(image_rgb / 255.0, transform_matrix.T)\n",
    "    return image_yiq\n",
    "\n",
    "def convert_yiq_to_rgb(image_yiq):\n",
    "    transform_matrix = np.array([[1.0, 0.956, 0.621],\n",
    "                                 [1.0, -0.272, -0.647],\n",
    "                                 [1.0, -1.106, 1.703]])\n",
    "    image_rgb = np.dot(image_yiq, transform_matrix.T)\n",
    "    image_rgb = np.clip(image_rgb, 0, 1)\n",
    "    return (image_rgb * 255).astype(np.uint8)\n",
    "\n",
    "image = cv2.imread('../DataBase/image7.jpg')\n",
    "# Charger l'image et la convertir en RGB\n",
    "image_bgr = cv2.imread('chemin_vers_votre_image.jpg')\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Convertir de RGB à YIQ\n",
    "image_yiq = convert_rgb_to_yiq(image_rgb)\n",
    "\n",
    "# Manipuler le canal Y ici pour tenter de réduire les ombres\n",
    "# Par exemple, augmenter la luminosité du canal Y\n",
    "y_channel = image_yiq[:, :, 0]  # Extrait le canal Y\n",
    "y_channel = np.clip(y_channel + 0.1, 0, 1)  # Augmente la luminosité de 10%\n",
    "image_yiq[:, :, 0] = y_channel\n",
    "\n",
    "# Convertir de YIQ à RGB pour l'affichage/sauvegarde\n",
    "image_rgb_modified = convert_yiq_to_rgb(image_yiq)\n",
    "\n",
    "# Convertir l'image résultante de RGB en BGR pour l'utilisation avec OpenCV\n",
    "image_bgr_modified = cv2.cvtColor(image_rgb_modified, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "cv2.imwrite('image_modifiee.jpg', image_bgr_modified)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
